{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import display markdown\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "  # Tiny Shakespeare Dataset\n",
       "  | Metric | Value |\n",
       "  | --- | --- |\n",
       "  | Number of characters | 1115394 |\n",
       "  | Number of unique characters | 65 |\n",
       "  | Number of lines | 40000 |\n",
       "  | Number of words | 202651 |\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import datasets\n",
    "\n",
    "# # load tiny shakespeare dataset\n",
    "# # dataset = datasets.load_dataset('tiny_shakespeare', cache_dir=\"cache\")\n",
    "\n",
    "with open(\"data/input.txt\", \"r\") as f:\n",
    "  text = f.read()\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "  # Tiny Shakespeare Dataset\n",
    "  | Metric | Value |\n",
    "  | --- | --- |\n",
    "  | Number of characters | {len(text)} |\n",
    "  | Number of unique characters | {len(set(text))} |\n",
    "  | Number of lines | {len(text.splitlines())} |\n",
    "  | Number of words | {len(text.split())} |\n",
    "  \"\"\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "  # Encoding and Decoding\n",
       "  | Text | Encoded | Decoded |\n",
       "  | --- | --- | --- |\n",
       "  | First Citi | [18, 47, 56, 57, 58, 1, 15, 47, 58, 47] | First Citi |\n",
       "  | t waking. | [58, 1, 61, 39, 49, 47, 52, 45, 8, 0] | t waking.\n",
       " |     \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "STOI = {ch: i for i, ch in enumerate(sorted(set(text)))}\n",
    "ITOS = {i: ch for ch, i in STOI.items()}\n",
    "\n",
    "def encode(text: str):\n",
    "  return [STOI[ch] for ch in text]\n",
    "\n",
    "def decode(indices: list):\n",
    "  return ''.join(ITOS[i] for i in indices)\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "  # Encoding and Decoding\n",
    "  | Text | Encoded | Decoded |\n",
    "  | --- | --- | --- |\n",
    "  | {text[:10]} | {encode(text[:10])} | {decode(encode(text[:10]))} |\n",
    "  | {text[-10:-1]} | {encode(text[-10:])} | {decode(encode(text[-10:]))} |     \n",
    "  \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 1, 58, 46, 43, 56, 43]\n",
      "hi there\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"hi there\"))\n",
    "print(decode(encode(\"hi there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
       "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
       "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
       "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
       "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
       "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text))\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "  # Train and Validation Data\n",
       "  | Data | Length |\n",
       "  | --- | --- |\n",
       "  | Train | 892315 |\n",
       "  | Validation | 223079 |\n",
       "  | **Total** | **1115394** |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split = int(len(data) * 0.8)\n",
    "train_data = data[:split]\n",
    "val_data = data[split:]\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "  # Train and Validation Data\n",
    "  | Data | Length |\n",
    "  | --- | --- |\n",
    "  | Train | {len(train_data)} |\n",
    "  | Validation | {len(val_data)} |\n",
    "  | **Total** | **{len(train_data) + len(val_data)}** |\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "  # Batch Data\n",
       "  | Data | Shape |\n",
       "  | --- | --- |\n",
       "  | Inputs | torch.Size([4, 8]) |\n",
       "  | Targets | torch.Size([4, 8]) |\n",
       "\n",
       "  Inputs: tensor([[58, 63,  8,  0,  0, 19, 24, 27],\n",
       "        [39, 59, 45, 46, 58,  1, 46, 43],\n",
       "        [49, 43, 57,  1, 53, 50, 42,  1],\n",
       "        [52, 41, 47, 43, 52, 58,  1, 56]])  \n",
       "  Targets: tensor([[63,  8,  0,  0, 19, 24, 27, 33],\n",
       "        [59, 45, 46, 58,  1, 46, 43,  1],\n",
       "        [43, 57,  1, 53, 50, 42,  1, 46],\n",
       "        [41, 47, 43, 52, 58,  1, 56, 47]]) \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(1337)       # Set the random seed for reproducibility\n",
    "CONTEXT_LENGTH = 8            # Maximum context length.\n",
    "BATCH_SIZE = 4                # Number of independent sequences to train on in parallel\n",
    "\n",
    "def get_batch(split: str):\n",
    "  data = train_data if split == 'train' else val_data\n",
    "  start_idx = torch.randint(0, len(data) - CONTEXT_LENGTH, (BATCH_SIZE,))\n",
    "  end_idx = start_idx + CONTEXT_LENGTH\n",
    "  inputs = [data[start:end] for start, end in zip(start_idx, end_idx)]\n",
    "  targets = [data[start+1:end+1] for start, end in zip(start_idx, end_idx)]\n",
    "  return torch.stack(inputs), torch.stack(targets)\n",
    "\n",
    "inputs, targets = get_batch('train')\n",
    "display(Markdown(f\"\"\"\n",
    "  # Batch Data\n",
    "  | Data | Shape |\n",
    "  | --- | --- |\n",
    "  | Inputs | {inputs.shape} |\n",
    "  | Targets | {targets.shape} |\n",
    "\n",
    "  Inputs: {inputs}  \n",
    "  Targets: {targets} \n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Contexts and Targets"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18]) -> 47\n",
      "tensor([18, 47]) -> 56\n",
      "tensor([18, 47, 56]) -> 57\n",
      "tensor([18, 47, 56, 57]) -> 58\n",
      "tensor([18, 47, 56, 57, 58]) -> 1\n",
      "tensor([18, 47, 56, 57, 58,  1]) -> 15\n",
      "tensor([18, 47, 56, 57, 58,  1, 15]) -> 47\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47]) -> 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "display(Markdown(\"### Contexts and Targets\"))\n",
    "for t in range(block_size):\n",
    "  context = x[:t+1]\n",
    "  target = y[t]\n",
    "  print(f\"{context} -> {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8]), torch.Size([4, 8]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.3323, -0.0872, -0.7470,  ..., -0.6716, -0.9572, -0.9594],\n",
      "        [-0.6722,  0.2322, -0.1632,  ...,  0.1390,  0.7560,  0.4296],\n",
      "        [-0.8109,  0.2410, -0.1139,  ...,  1.4509,  0.1836,  0.3064],\n",
      "        ...,\n",
      "        [ 0.3323, -0.0872, -0.7470,  ..., -0.6716, -0.9572, -0.9594],\n",
      "        [-0.1679,  0.5602,  0.6467,  ...,  0.1522,  0.5109,  0.0990],\n",
      "        [ 0.3323, -0.0872, -0.7470,  ..., -0.6716, -0.9572, -0.9594]],\n",
      "       grad_fn=<ViewBackward0>), tensor(4.5193, grad_fn=<NllLossBackward0>))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nSr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "  def __init__(self, vocab_size: int):\n",
    "    super().__init__()\n",
    "    self.embeddings = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "  def forward(self, idx, targets=None):\n",
    "\n",
    "    logits = self.embeddings(idx)\n",
    "    if targets is None:\n",
    "      loss = None\n",
    "\n",
    "    else:\n",
    "      B, T, C = logits.shape\n",
    "      logits = logits.view(B*T, C)\n",
    "      targets = targets.view(B*T)\n",
    "      loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "    return logits, loss\n",
    "  \n",
    "  def generate(self, idx, max_new_tokens):\n",
    "    \"\"\"\n",
    "      idx: (B, T)\n",
    "    \"\"\"\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "      logits, loss = self(idx)\n",
    "\n",
    "      logits = logits[:, -1, :]\n",
    "\n",
    "      probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "      idx_next = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "      idx = torch.cat([idx, idx_next], dim=-1)\n",
    "\n",
    "    return idx\n",
    "  \n",
    "vocab_size = len(STOI)\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "print(out := model(xb, yb))\n",
    "\n",
    "idx = torch.zeros( (1, 1), dtype=torch.long)\n",
    "decode(model.generate(idx, max_new_tokens=100)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(optimizer := torch.optim.Adam(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TERYourand sted crd ICHador pengle y leathe, sher I chad timise wiselimod\n",
      "BEORI ld thy s\n",
      "The,\n",
      "\n",
      "Pomy, s sknacar se e wes, ofal t whenouroutal,\n",
      "\n",
      "\n",
      "DIENRoug whent\n",
      "S:\n",
      "ENGo w, u in omath ng! me chay othy mat sioubo ind mete l shawanod t t f chefithy t d nts thompo sendyount wo st me wiso ithey gnou whind th t howith t ar t\n",
      "I'd.\n",
      "loong hay theral fimpat bu, heiteceer ong\n",
      "ASecoutou ar,\n",
      "CENENERE ped? d, fre\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for steps in range(100000):\n",
    "  xb, yb = get_batch('train')\n",
    "  logits, loss = model(xb, yb)\n",
    "  optimizer.zero_grad(set_to_none=True)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  # if steps % 100 == 0:\n",
    "  #   print(f\"Step: {steps:4} Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(decode(model.generate(idx=torch.zeros((1,1), dtype=torch.long), max_new_tokens=400)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Yeres! f cooue pu wes N hat pemese bamerte we ono, cthouthe wangeakigl hin asedes m al wal g byo y a\n"
     ]
    }
   ],
   "source": [
    "print(decode(model.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
